{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auuaEk9iaMyg"
      },
      "source": [
        "Copyright (c) Meta Platforms, Inc. and affiliates. All rights reserved. This source code is licensed under the license found in the LICENSE file in the root directory of this source tree.\n",
        "\n",
        "# Video Seal Inference\n",
        "\n",
        "[[`arXiv`](https://arxiv.org/abs/2412.09492)]\n",
        "[[`Colab`](https://colab.research.google.com/github/facebookresearch/videoseal/blob/main/notebooks/colab.ipynb)]\n",
        "[[`Demo`](https://aidemos.meta.com/videoseal)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwKcdtqg-iDn"
      },
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktbpIy3maMyi"
      },
      "source": [
        "Clone repository and install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXXEkRqEaMyi",
        "outputId": "bc53ec68-989c-46f1-9b4a-9ba487af86cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'videoseal' already exists and is not an empty directory.\n",
            "/content/videoseal\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/facebookresearch/videoseal.git\n",
        "%cd videoseal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7HepUuOaMyj"
      },
      "source": [
        "Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmrcsfF8aMyj",
        "outputId": "1eeeb125-e5bd-4f16-bdc1-37753cd55c8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.2.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (4.11.0.86)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (2.3.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (0.8.1)\n",
            "Requirement already satisfied: lpips in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (0.1.4)\n",
            "Requirement already satisfied: timm==0.9.16 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (0.9.16)\n",
            "Requirement already satisfied: pre-commit in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (4.2.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (6.17.1)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (2.0.8)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (1.8.0)\n",
            "Requirement already satisfied: pyav==13.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (13.0.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (0.25.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (4.67.1)\n",
            "Requirement already satisfied: pytorch_msssim in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (1.0.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 17)) (2.18.0)\n",
            "Requirement already satisfied: calflops in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 18)) (0.3.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 19)) (4.49.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 20)) (0.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 25)) (1.14.1)\n",
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 26)) (0.2.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from timm==0.9.16->-r requirements.txt (line 6)) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm==0.9.16->-r requirements.txt (line 6)) (0.21.0+cu124)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm==0.9.16->-r requirements.txt (line 6)) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm==0.9.16->-r requirements.txt (line 6)) (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 1)) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 1)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 1)) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 1)) (2025.1)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf->-r requirements.txt (line 3)) (4.9.3)\n",
            "Requirement already satisfied: cfgv>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pre-commit->-r requirements.txt (line 7)) (3.4.0)\n",
            "Requirement already satisfied: identify>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from pre-commit->-r requirements.txt (line 7)) (2.6.9)\n",
            "Requirement already satisfied: nodeenv>=0.11.1 in /usr/local/lib/python3.11/dist-packages (from pre-commit->-r requirements.txt (line 7)) (1.9.1)\n",
            "Requirement already satisfied: virtualenv>=20.10.0 in /usr/local/lib/python3.11/dist-packages (from pre-commit->-r requirements.txt (line 7)) (20.29.3)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r requirements.txt (line 8)) (1.8.0)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r requirements.txt (line 8)) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r requirements.txt (line 8)) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r requirements.txt (line 8)) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r requirements.txt (line 8)) (1.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r requirements.txt (line 8)) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r requirements.txt (line 8)) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r requirements.txt (line 8)) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r requirements.txt (line 8)) (6.4.2)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r requirements.txt (line 8)) (5.7.1)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pycocotools->-r requirements.txt (line 9)) (3.10.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->-r requirements.txt (line 13)) (3.4.2)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image->-r requirements.txt (line 13)) (11.1.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->-r requirements.txt (line 13)) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->-r requirements.txt (line 13)) (2025.3.13)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->-r requirements.txt (line 13)) (0.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 17)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 17)) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 17)) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 17)) (5.29.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 17)) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 17)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 17)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 17)) (3.1.3)\n",
            "Requirement already satisfied: accelerate>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from calflops->-r requirements.txt (line 18)) (1.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 19)) (3.18.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 19)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 19)) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 19)) (0.21.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python->-r requirements.txt (line 26)) (1.0.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm==0.9.16->-r requirements.txt (line 6)) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm==0.9.16->-r requirements.txt (line 6)) (4.12.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 8)) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 8)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 8)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 8)) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 8)) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 8)) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 8)) (4.9.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel->-r requirements.txt (line 8)) (5.7.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 9)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 9)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 9)) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 9)) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 9)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->timm==0.9.16->-r requirements.txt (line 6)) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm==0.9.16->-r requirements.txt (line 6)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm==0.9.16->-r requirements.txt (line 6)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm==0.9.16->-r requirements.txt (line 6)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->timm==0.9.16->-r requirements.txt (line 6)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->timm==0.9.16->-r requirements.txt (line 6)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->timm==0.9.16->-r requirements.txt (line 6)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->timm==0.9.16->-r requirements.txt (line 6)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->timm==0.9.16->-r requirements.txt (line 6)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->timm==0.9.16->-r requirements.txt (line 6)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->timm==0.9.16->-r requirements.txt (line 6)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->timm==0.9.16->-r requirements.txt (line 6)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm==0.9.16->-r requirements.txt (line 6)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm==0.9.16->-r requirements.txt (line 6)) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm==0.9.16->-r requirements.txt (line 6)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->timm==0.9.16->-r requirements.txt (line 6)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->timm==0.9.16->-r requirements.txt (line 6)) (1.3.0)\n",
            "Requirement already satisfied: distlib<1,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from virtualenv>=20.10.0->pre-commit->-r requirements.txt (line 7)) (0.3.9)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.11/dist-packages (from virtualenv>=20.10.0->pre-commit->-r requirements.txt (line 7)) (4.3.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 17)) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->-r requirements.txt (line 19)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->-r requirements.txt (line 19)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->-r requirements.txt (line 19)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->-r requirements.txt (line 19)) (2025.1.31)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->-r requirements.txt (line 8)) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->-r requirements.txt (line 8)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel->-r requirements.txt (line 8)) (0.2.13)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q16r0X1CaMyk"
      },
      "source": [
        "## Imports and loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPfZw_FAaMyk",
        "outputId": "7b685a8c-4d1b-4eb8-8858-5e15a49701c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/videoseal\n"
          ]
        }
      ],
      "source": [
        "%cd /content/videoseal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZIicYPSXaMyl"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation\n",
        "import logging\n",
        "logging.getLogger(\"matplotlib.image\").setLevel(logging.ERROR)\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import ffmpeg\n",
        "import os\n",
        "import cv2\n",
        "import subprocess\n",
        "\n",
        "import torch\n",
        "\n",
        "from videoseal.evals.metrics import bit_accuracy\n",
        "from videoseal.models import Videoseal\n",
        "from videoseal.utils.cfg import setup_model_from_model_card\n",
        "\n",
        "\n",
        "def get_video_info(input_path):\n",
        "    # Open the video file\n",
        "    video = cv2.VideoCapture(input_path)\n",
        "\n",
        "    # Get video properties\n",
        "    width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = video.get(cv2.CAP_PROP_FPS)\n",
        "    codec = int(video.get(cv2.CAP_PROP_FOURCC))\n",
        "    num_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # Decode codec to human-readable form\n",
        "    codec_str = \"\".join([chr((codec >> 8 * i) & 0xFF) for i in range(4)])\n",
        "\n",
        "    video.release()  # Close the video file\n",
        "\n",
        "    return {\n",
        "        \"width\": width,\n",
        "        \"height\": height,\n",
        "        \"fps\": fps,\n",
        "        \"codec\": codec_str,\n",
        "        \"num_frames\": num_frames\n",
        "    }\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tGZxcKuaMyl"
      },
      "source": [
        "## Load the model\n",
        "\n",
        "The videoseal library provides pretrained models for embedding and extracting watermarks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_8BMj5UaMym",
        "outputId": "f707eb10-abce-4165-c85c-b816a37f840b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File https://dl.fbaipublicfiles.com/videoseal/y_256b_img.pth downloaded successfully to /content/videoseal/ckpts/y_256b_img.pth\n",
            "Model loaded successfully from /content/videoseal/ckpts/y_256b_img.pth with message: <All keys matched successfully>\n"
          ]
        }
      ],
      "source": [
        "# Load the VideoSeal model\n",
        "model = setup_model_from_model_card(\"videoseal\")\n",
        "\n",
        "# Set the model to evaluation mode and move it to the selected device\n",
        "model = model.eval()\n",
        "model = model.to(device)\n",
        "model.compile()\n",
        "\n",
        "# Setup the step size. Bigger step size makes embedding faster but loses a bit of robustness.\n",
        "model.step_size = 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDB8D9e6aMym"
      },
      "source": [
        "## Embedding\n",
        "\n",
        "The embedding process is the process of hiding the watermark in the video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WeT-7WzXaMym"
      },
      "outputs": [],
      "source": [
        "def embed_video_clip(\n",
        "    model: Videoseal,\n",
        "    clip: np.ndarray,\n",
        "    msgs: torch.Tensor\n",
        ") -> np.ndarray:\n",
        "    clip_tensor = torch.tensor(clip, dtype=torch.float32).permute(0, 3, 1, 2) / 255.0\n",
        "    outputs = model.embed(clip_tensor, msgs=msgs, is_video=True, lowres_attenuation=True)\n",
        "    processed_clip = outputs[\"imgs_w\"]\n",
        "    processed_clip = (processed_clip * 255.0).byte().permute(0, 2, 3, 1).numpy()\n",
        "    return processed_clip\n",
        "\n",
        "def embed_video(\n",
        "    model: Videoseal,\n",
        "    input_path: str,\n",
        "    output_path: str,\n",
        "    chunk_size: int,\n",
        "    crf: int = 23\n",
        ") -> None:\n",
        "    # Read video dimensions\n",
        "    video_info = get_video_info(input_path)\n",
        "    width = int(video_info['width'])\n",
        "    height = int(video_info['height'])\n",
        "    fps = float(video_info['fps'])\n",
        "    codec = video_info['codec']\n",
        "    num_frames = int(video_info['num_frames'])\n",
        "\n",
        "    # Open the input video\n",
        "    process1 = (\n",
        "        ffmpeg\n",
        "        .input(input_path)\n",
        "        .output('pipe:', format='rawvideo', pix_fmt='rgb24', s='{}x{}'.format(width, height), r=fps)\n",
        "        .run_async(pipe_stdout=True, pipe_stderr=subprocess.PIPE)\n",
        "    )\n",
        "    # Open the output video\n",
        "    process2 = (\n",
        "        ffmpeg\n",
        "        .input('pipe:', format='rawvideo', pix_fmt='rgb24', s='{}x{}'.format(width, height), r=fps)\n",
        "        .output(output_path, vcodec='libx264', pix_fmt='yuv420p', r=fps, crf=crf)\n",
        "        .overwrite_output()\n",
        "        .run_async(pipe_stdin=True, pipe_stderr=subprocess.PIPE)\n",
        "    )\n",
        "\n",
        "    # Create a random message\n",
        "    msgs = model.get_random_msg()\n",
        "    with open(output_path.replace(\".mp4\", \".txt\"), \"w\") as f:\n",
        "        f.write(\"\".join([str(msg.item()) for msg in msgs[0]]))\n",
        "\n",
        "    # Process the video\n",
        "    frame_size = width * height * 3\n",
        "    chunk = np.zeros((chunk_size, height, width, 3), dtype=np.uint8)\n",
        "    frame_count = 0\n",
        "    pbar = tqdm(total=num_frames, desc=\"Watermark embedding\")\n",
        "    while True:\n",
        "        in_bytes = process1.stdout.read(frame_size)\n",
        "        if not in_bytes:\n",
        "            break\n",
        "        frame = np.frombuffer(in_bytes, np.uint8).reshape([height, width, 3])\n",
        "        chunk[frame_count % chunk_size] = frame\n",
        "        frame_count += 1\n",
        "        pbar.update(1)\n",
        "        if frame_count % chunk_size == 0:\n",
        "            processed_frame = embed_video_clip(model, chunk, msgs)\n",
        "            process2.stdin.write(processed_frame.tobytes())\n",
        "    process1.stdout.close()\n",
        "    process2.stdin.close()\n",
        "    process1.wait()\n",
        "    process2.wait()\n",
        "\n",
        "    return msgs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKOJP7GTa1xO"
      },
      "source": [
        "You are free to upload any video and change the `video_path`.\n",
        "\n",
        "You can look at the watermark video output in the folder `outputs`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XX1TKDega1Wg",
        "outputId": "807f8691-b1ac-4708-e17d-3df551f552ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Watermark embedding: 100%|██████████| 256/256 [02:44<00:00,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saved watermarked video to ./outputs/1.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Path to the input video\n",
        "video_path = \"./assets/videos/1.mp4\"\n",
        "\n",
        "# Create the output directory and path\n",
        "output_dir = \"./outputs\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "output_path = os.path.join(output_dir, os.path.basename(video_path))\n",
        "\n",
        "# Embed the watermark inside the video with a random msg\n",
        "msgs_ori = embed_video(model, video_path, output_path, 16)\n",
        "print(f\"\\nSaved watermarked video to {output_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJPpKOMDaMym"
      },
      "source": [
        "## Extraction\n",
        "\n",
        "Load the video output from the embedding process and extract the watermark."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wJxWT4F6aMym"
      },
      "outputs": [],
      "source": [
        "def detect_video_clip(\n",
        "    model: Videoseal,\n",
        "    clip: np.ndarray\n",
        ") -> torch.Tensor:\n",
        "    clip_tensor = torch.tensor(clip, dtype=torch.float32).permute(0, 3, 1, 2) / 255.0\n",
        "    outputs = model.detect(clip_tensor, is_video=True)\n",
        "    output_bits = outputs[\"preds\"][:, 1:]  # exclude the first which may be used for detection\n",
        "    return output_bits\n",
        "\n",
        "def detect_video(\n",
        "    model: Videoseal,\n",
        "    input_path: str,\n",
        "    num_frames_for_extraction: int,\n",
        "    chunk_size: int\n",
        ") -> None:\n",
        "    # Read video dimensions\n",
        "    video_info = get_video_info(input_path)\n",
        "    width = int(video_info['width'])\n",
        "    height = int(video_info['height'])\n",
        "    num_frames = int(video_info['num_frames'])\n",
        "\n",
        "    # Open the input video\n",
        "    process1 = (\n",
        "        ffmpeg\n",
        "        .input(input_path)\n",
        "        .output('pipe:', format='rawvideo', pix_fmt='rgb24')\n",
        "        .run_async(pipe_stdout=True, pipe_stderr=subprocess.PIPE)\n",
        "    )\n",
        "\n",
        "    # Process the video\n",
        "    frame_size = width * height * 3\n",
        "    chunk = np.zeros((chunk_size, height, width, 3), dtype=np.uint8)\n",
        "    frame_count = 0\n",
        "    soft_msgs = []\n",
        "    pbar = tqdm(total=num_frames, desc=\"Watermark extraction\")\n",
        "    while True:\n",
        "        if frame_count >= num_frames_for_extraction:\n",
        "            break\n",
        "        in_bytes = process1.stdout.read(frame_size)\n",
        "        if not in_bytes:\n",
        "            break\n",
        "        frame = np.frombuffer(in_bytes, np.uint8).reshape([height, width, 3])\n",
        "        chunk[frame_count % chunk_size] = frame\n",
        "        frame_count += 1\n",
        "        pbar.update(1)\n",
        "        if frame_count % chunk_size == 0:\n",
        "            soft_msgs.append(detect_video_clip(model, chunk))\n",
        "    process1.stdout.close()\n",
        "    process1.wait()\n",
        "\n",
        "    soft_msgs = torch.cat(soft_msgs, dim=0)\n",
        "    soft_msgs = soft_msgs.mean(dim=0)  # Average the predictions across all frames\n",
        "    return soft_msgs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "qxKfPegN-iDq",
        "outputId": "e44b690f-43a1-4f2a-91b6-4c1edf9316fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Watermark extraction:  12%|█▎        | 32/256 [00:19<02:15,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Binary message extracted with 99.2% bit accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Detect the watermark\n",
        "num_frames_for_extraction = 32\n",
        "soft_msgs = detect_video(model, output_path, num_frames_for_extraction, 16)\n",
        "bit_acc = bit_accuracy(soft_msgs, msgs_ori).item() * 100\n",
        "print(f\"\\nBinary message extracted with {bit_acc:.1f}% bit accuracy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgNFCmy9-iDq"
      },
      "source": [
        "## Run other baselines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpCtMaBF-iDr"
      },
      "source": [
        "To download other checkpoints, you can run the following command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "MsDX_uGqcP5d",
        "outputId": "9f55a2f8-d4b2-494a-ecf0-c8cb6f2ad28d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.29.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.1.31)\n",
            "Fetching 11 files:   0% 0/11 [00:00<?, ?it/s]Downloading '.gitattributes' to '.cache/models--tangtianzhong--img-wm-torchscript/blobs/a6344aac8c09253b3b630fb776ae94478aa0275b.incomplete'\n",
            "Downloading 'cin_nsm_decoder.pt' to '.cache/models--tangtianzhong--img-wm-torchscript/blobs/60cbc933a974f0258d3cfa947404c0e92027a29c3769edba34d90718301f9e8d.incomplete'\n",
            "Downloading 'mbrs_256_m256_decoder.pt' to '.cache/models--tangtianzhong--img-wm-torchscript/blobs/9835526c99330b84f4910ab79f64d6da398ac2eaed9731f14b8e8707d775a70d.incomplete'\n",
            "Downloading 'hidden_decoder_48b.pt' to '.cache/models--tangtianzhong--img-wm-torchscript/blobs/fb7571b93edeac06ba6d403d5bdbe3744ca82852cf1e00d2e2b7ec33376f8349.incomplete'\n",
            "Downloading 'hidden_encoder_48b.pt' to '.cache/models--tangtianzhong--img-wm-torchscript/blobs/6a7c78241837a455db3d160134fa25e60ec225b548b5d6aab69a30cd3f7b19c3.incomplete'\n",
            "Downloading 'cin_nsm_encoder.pt' to '.cache/models--tangtianzhong--img-wm-torchscript/blobs/5db5bdf2dc77dcf4a811b23185a031e86a6b60d727855dee1d17ba716f1d762b.incomplete'\n",
            "Downloading 'trustmark_decoder_q.pt' to '.cache/models--tangtianzhong--img-wm-torchscript/blobs/c1e22e4a12c095e6a8f59c0b4fe35f2c09a6a071a62548b1fd6aae37f6fd85ef.incomplete'\n",
            "\n",
            ".gitattributes: 100% 1.52k/1.52k [00:00<00:00, 6.97MB/s]\n",
            "Download complete. Moving file to .cache/models--tangtianzhong--img-wm-torchscript/blobs/a6344aac8c09253b3b630fb776ae94478aa0275b\n",
            "Fetching 11 files:   9% 1/11 [00:00<00:01,  7.05it/s]Downloading 'mbrs_256_m256_encoder.pt' to '.cache/models--tangtianzhong--img-wm-torchscript/blobs/cabf5317340901e7fcc946428a16c3000f66fbb1a297e8fed114dcf540455bab.incomplete'\n",
            "Downloading 'trustmark_encoder_q.pt' to '.cache/models--tangtianzhong--img-wm-torchscript/blobs/9502c4d6d0f0dbbefead5257f84b123238c79b68342143403011bcb8eb435eb9.incomplete'\n",
            "\n",
            "cin_nsm_encoder.pt:   0% 0.00/25.5M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "trustmark_decoder_q.pt:   0% 0.00/95.3M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "cin_nsm_decoder.pt:   0% 0.00/138M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "hidden_decoder_48b.pt:   0% 0.00/1.21M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mbrs_256_m256_encoder.pt:   0% 0.00/2.38M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mbrs_256_m256_decoder.pt:   0% 0.00/81.2M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "hidden_decoder_48b.pt: 100% 1.21M/1.21M [00:00<00:00, 11.8MB/s]\n",
            "Download complete. Moving file to .cache/models--tangtianzhong--img-wm-torchscript/blobs/fb7571b93edeac06ba6d403d5bdbe3744ca82852cf1e00d2e2b7ec33376f8349\n",
            "mbrs_256_m256_encoder.pt: 100% 2.38M/2.38M [00:00<00:00, 22.5MB/s]\n",
            "Download complete. Moving file to .cache/models--tangtianzhong--img-wm-torchscript/blobs/cabf5317340901e7fcc946428a16c3000f66fbb1a297e8fed114dcf540455bab\n",
            "hidden_encoder_48b.pt: 100% 755k/755k [00:00<00:00, 11.3MB/s]\n",
            "Download complete. Moving file to .cache/models--tangtianzhong--img-wm-torchscript/blobs/6a7c78241837a455db3d160134fa25e60ec225b548b5d6aab69a30cd3f7b19c3\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "trustmark_encoder_q.pt:   0% 0.00/34.7M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'wam_decoder.pt' to '.cache/models--tangtianzhong--img-wm-torchscript/blobs/a245971eeef46f4c27083ee79f5027ca67117b579e9e8ec56105e167f01912fb.incomplete'\n",
            "\n",
            "cin_nsm_encoder.pt:  41% 10.5M/25.5M [00:00<00:00, 39.5MB/s]\u001b[ADownloading 'wam_encoder.pt' to '.cache/models--tangtianzhong--img-wm-torchscript/blobs/d5101989c3729529908c4596b5fd78045333639d7ffe4ae45699b28224ada48c.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "cin_nsm_decoder.pt:   8% 10.5M/138M [00:00<00:03, 36.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "trustmark_decoder_q.pt:  11% 10.5M/95.3M [00:00<00:02, 34.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mbrs_256_m256_decoder.pt:  13% 10.5M/81.2M [00:00<00:01, 41.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "trustmark_encoder_q.pt:  30% 10.5M/34.7M [00:00<00:00, 40.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wam_encoder.pt:   0% 0.00/4.57M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wam_decoder.pt:   0% 0.00/373M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "wam_encoder.pt: 100% 4.57M/4.57M [00:00<00:00, 34.7MB/s]\n",
            "Download complete. Moving file to .cache/models--tangtianzhong--img-wm-torchscript/blobs/d5101989c3729529908c4596b5fd78045333639d7ffe4ae45699b28224ada48c\n",
            "\n",
            "\n",
            "\n",
            "cin_nsm_decoder.pt:  15% 21.0M/138M [00:00<00:03, 36.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mbrs_256_m256_decoder.pt:  26% 21.0M/81.2M [00:00<00:01, 36.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "trustmark_decoder_q.pt:  22% 21.0M/95.3M [00:00<00:02, 34.0MB/s]\u001b[A\u001b[A\n",
            "cin_nsm_encoder.pt: 100% 25.5M/25.5M [00:00<00:00, 36.4MB/s]\n",
            "Download complete. Moving file to .cache/models--tangtianzhong--img-wm-torchscript/blobs/5db5bdf2dc77dcf4a811b23185a031e86a6b60d727855dee1d17ba716f1d762b\n",
            "\n",
            "\n",
            "\n",
            "cin_nsm_decoder.pt:  23% 31.5M/138M [00:00<00:02, 50.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "trustmark_encoder_q.pt:  60% 21.0M/34.7M [00:00<00:00, 38.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wam_decoder.pt:   3% 10.5M/373M [00:00<00:09, 37.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mbrs_256_m256_decoder.pt:  39% 31.5M/81.2M [00:00<00:01, 45.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "trustmark_decoder_q.pt:  33% 31.5M/95.3M [00:00<00:01, 42.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "trustmark_encoder_q.pt:  91% 31.5M/34.7M [00:00<00:00, 44.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "cin_nsm_decoder.pt:  30% 41.9M/138M [00:00<00:01, 49.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wam_decoder.pt:   6% 21.0M/373M [00:00<00:08, 40.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "trustmark_decoder_q.pt:  44% 41.9M/95.3M [00:01<00:01, 42.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "trustmark_encoder_q.pt: 100% 34.7M/34.7M [00:00<00:00, 39.5MB/s]\n",
            "Download complete. Moving file to .cache/models--tangtianzhong--img-wm-torchscript/blobs/9502c4d6d0f0dbbefead5257f84b123238c79b68342143403011bcb8eb435eb9\n",
            "\n",
            "\n",
            "\n",
            "cin_nsm_decoder.pt:  38% 52.4M/138M [00:01<00:01, 53.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wam_decoder.pt:   8% 31.5M/373M [00:00<00:06, 54.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mbrs_256_m256_decoder.pt:  65% 52.4M/81.2M [00:01<00:00, 51.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "cin_nsm_decoder.pt:  46% 62.9M/138M [00:01<00:01, 62.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wam_decoder.pt:  11% 41.9M/373M [00:00<00:05, 65.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "trustmark_decoder_q.pt:  55% 52.4M/95.3M [00:01<00:00, 46.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "cin_nsm_decoder.pt:  53% 73.4M/138M [00:01<00:00, 71.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mbrs_256_m256_decoder.pt:  77% 62.9M/81.2M [00:01<00:00, 58.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wam_decoder.pt:  14% 52.4M/373M [00:00<00:04, 73.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "trustmark_decoder_q.pt:  66% 62.9M/95.3M [00:01<00:00, 54.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mbrs_256_m256_decoder.pt:  90% 73.4M/81.2M [00:01<00:00, 67.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "cin_nsm_decoder.pt:  68% 94.4M/138M [00:01<00:00, 86.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wam_decoder.pt:  20% 73.4M/373M [00:01<00:03, 91.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "mbrs_256_m256_decoder.pt: 100% 81.2M/81.2M [00:01<00:00, 69.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "mbrs_256_m256_decoder.pt: 100% 81.2M/81.2M [00:01<00:00, 54.2MB/s]\n",
            "Download complete. Moving file to .cache/models--tangtianzhong--img-wm-torchscript/blobs/9835526c99330b84f4910ab79f64d6da398ac2eaed9731f14b8e8707d775a70d\n",
            "\n",
            "\n",
            "\n",
            "cin_nsm_decoder.pt:  84% 115M/138M [00:01<00:00, 99.8MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wam_decoder.pt:  25% 94.4M/373M [00:01<00:02, 97.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "trustmark_decoder_q.pt: 100% 95.3M/95.3M [00:01<00:00, 55.2MB/s]\n",
            "Download complete. Moving file to .cache/models--tangtianzhong--img-wm-torchscript/blobs/c1e22e4a12c095e6a8f59c0b4fe35f2c09a6a071a62548b1fd6aae37f6fd85ef\n",
            "\n",
            "\n",
            "\n",
            "cin_nsm_decoder.pt:  91% 126M/138M [00:01<00:00, 99.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wam_decoder.pt:  28% 105M/373M [00:01<00:03, 86.4MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "cin_nsm_decoder.pt:  99% 136M/138M [00:01<00:00, 89.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cin_nsm_decoder.pt: 100% 138M/138M [00:02<00:00, 66.3MB/s]\n",
            "Download complete. Moving file to .cache/models--tangtianzhong--img-wm-torchscript/blobs/60cbc933a974f0258d3cfa947404c0e92027a29c3769edba34d90718301f9e8d\n",
            "Fetching 11 files:  18% 2/11 [00:02<00:12,  1.42s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wam_decoder.pt:  34% 126M/373M [00:01<00:03, 61.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wam_decoder.pt:  37% 136M/373M [00:07<00:36, 6.52MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wam_decoder.pt:  39% 147M/373M [00:18<01:31, 2.48MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wam_decoder.pt:  39% 147M/373M [00:29<01:31, 2.48MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wam_decoder.pt:  42% 157M/373M [00:49<04:06, 878kB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wam_decoder.pt:  48% 178M/373M [00:49<02:03, 1.59MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wam_decoder.pt:  53% 199M/373M [00:49<01:07, 2.58MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wam_decoder.pt:  59% 220M/373M [00:49<00:38, 3.98MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wam_decoder.pt:  65% 241M/373M [00:50<00:22, 5.92MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wam_decoder.pt:  70% 262M/373M [00:50<00:12, 8.59MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wam_decoder.pt:  76% 283M/373M [00:50<00:07, 12.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wam_decoder.pt:  81% 304M/373M [00:50<00:04, 16.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wam_decoder.pt:  87% 325M/373M [00:50<00:02, 23.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wam_decoder.pt:  93% 346M/373M [00:51<00:00, 30.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wam_decoder.pt: 100% 373M/373M [00:51<00:00, 7.27MB/s]\n",
            "Download complete. Moving file to .cache/models--tangtianzhong--img-wm-torchscript/blobs/a245971eeef46f4c27083ee79f5027ca67117b579e9e8ec56105e167f01912fb\n",
            "Fetching 11 files: 100% 11/11 [00:52<00:00,  4.74s/it]\n",
            ".cache/models--tangtianzhong--img-wm-torchscript/snapshots/845dc751783db2a03a4b14ea600b0a4a9aba89aa\n",
            "mkdir: cannot create directory ‘ckpts’: File exists\n"
          ]
        }
      ],
      "source": [
        "!pip install huggingface_hub\n",
        "!huggingface-cli download tangtianzhong/img-wm-torchscript --cache-dir .cache\n",
        "!mkdir ckpts\n",
        "!cp .cache/models--tangtianzhong--img-wm-torchscript/snapshots/845dc751783db2a03a4b14ea600b0a4a9aba89aa/*.pt ckpts/\n",
        "!rm -rf .cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "mnl76B-a-iDr"
      },
      "outputs": [],
      "source": [
        "from videoseal.utils.cfg import setup_model_from_checkpoint\n",
        "\n",
        "model = setup_model_from_checkpoint(\"baseline/trustmark\")\n",
        "model = model.eval()\n",
        "model = model.to(device)\n",
        "model.compile()\n",
        "\n",
        "model.chunk_size = 32  # embed 32 frames/imgs at a time\n",
        "model.step_size = 4  # propagate the wm to 4 next frame/img\n",
        "# model.blender.scaling_w *= 1.5  # imperceptibility/robustness trade-off"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDekA4in-iDr"
      },
      "source": [
        "### Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSWqv_eb-iDr",
        "outputId": "a5cf1162-3511-4a6a-b66c-963fc11b18e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Watermark embedding:  42%|████▏     | 108/256 [00:58<01:01,  2.42it/s]"
          ]
        }
      ],
      "source": [
        "# Path to the input video\n",
        "video_path = \"./assets/videos/1.mp4\"\n",
        "\n",
        "# Create the output directory and path\n",
        "output_dir = \"./outputs\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "output_path = os.path.join(output_dir, os.path.basename(video_path))\n",
        "\n",
        "# Embed the watermark inside the video with a random msg\n",
        "msgs_ori = embed_video(model, video_path, output_path, 16)\n",
        "print(f\"\\nSaved watermarked video to {output_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUgDSyBy-iDr"
      },
      "source": [
        "### Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZfl1YoM-iDr"
      },
      "outputs": [],
      "source": [
        "# Detect the watermark\n",
        "num_frames_for_extraction = 32\n",
        "soft_msgs = detect_video(model, output_path, num_frames_for_extraction, 16)\n",
        "bit_acc = bit_accuracy(soft_msgs, msgs_ori).item() * 100\n",
        "print(f\"\\nBinary message extracted with {bit_acc:.1f}% bit accuracy\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}